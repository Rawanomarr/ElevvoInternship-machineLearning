# -*- coding: utf-8 -*-
"""StudentPredictions.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GQ1erZrDQnlD3y-Z7lZYXs-oLHspgGWA
"""

#imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error , r2_score , mean_absolute_error

#reading dataset & dropping null values from main columns that can affect the training process
# there are other null values in other columns found after searching in the CSV file
df = pd.read_csv("StudentPerformanceFactors.csv")
df = df.dropna(axis=0)

#train/split
X = df[["Hours_Studied"]]
y = df['Exam_Score']

X.describe() #getting stat summary for x and y below

X.head() #displaying first 5 values

y.describe()

y.head()

X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42) #keeping 20% to test after training the other 80%

model = LinearRegression() #creating a linear reg model to fit x train and y train on it
model.fit(X_train, y_train)

y_pred=model.predict(X_test) #predicting

plt.scatter(X_test, y_test, color='blue', label='Actual Data', alpha=0.6) #creating a plot to show the actual data and the prediction so it can be visualized better
plt.plot(X_test, y_pred, color='red', label='Linear Regression')
plt.xlabel("Study Hours")
plt.ylabel("Exam Score")
plt.title("Linear Regression Prediction")
plt.legend()
plt.show()

#evaluating the model performance by using metrics : variance , mean absolute & square error
meanAbs = mean_absolute_error(y_test, y_pred)
meanSq = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(meanSq)
variance = r2_score(y_test, y_pred)

print(f"Mean Absolute Error: {meanAbs:.2f}")
print(f"Mean Squared Error: {meanSq:.2f}")
print(f"Root Mean Squared Error: {rmse:.2f}")
print(f"Variance Score: {variance:.2f}")

# bonus:polynomial regression pf 2nd degree
poly = PolynomialFeatures(degree=2)
#training
X_poly = poly.fit_transform(X_train)
#testing
X_poly_test = poly.transform(X_test)

#choosing model then fitting and predicting
poly_model = LinearRegression()
poly_model.fit(X_poly, y_train)
y_poly_pred = poly_model.predict(X_poly_test)

# Transform features for polynomial regression
X_poly_test = poly.transform(X_test)
y_pred_poly = poly_model.predict(X_poly_test)


# Plot
plt.scatter(X_test, y_test, color='blue', label='Actual Data', alpha=0.6)
plt.plot(X_test, y_poly_pred, color='green', label='Polynomial Regression')
plt.xlabel("Study Hours")
plt.ylabel("Exam Score")
plt.title("Polynomial Regression Prediction")
plt.legend()
plt.show()

#evaluating the model performance by using metrics : variance , mean absolute & square error
meanAbs = mean_absolute_error(y_test, y_poly_pred)
meanSq = mean_squared_error(y_test,  y_poly_pred)
rmse = np.sqrt(meanSq)
variance = r2_score(y_test, y_poly_pred)

print(f"Mean Absolute Error: {meanAbs:.2f}")
print(f"Mean Squared Error: {meanSq:.2f}")
print(f"Root Mean Squared Error: {rmse:.2f}")
print(f"Variance Score: {variance:.2f}")